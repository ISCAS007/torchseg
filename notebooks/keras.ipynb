{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as KL\n",
    "import torch.utils.data as TD\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils.metrics import runningScore,get_scores\n",
    "from dataset.cityscapes import cityscapes\n",
    "from models.keras.semantic_segmentation import SS\n",
    "\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "# 设置session\n",
    "KTF.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SS.get_default_config()\n",
    "config.model.activation='softmax'\n",
    "config.training.log_dir='/home/yzbx/tmp/logs/keras'\n",
    "config.dataset.resize_shape=(36,36)\n",
    "config.model.input_shape=(36,36)\n",
    "\n",
    "class_number = config.model.class_number\n",
    "input_size=config.model.input_shape.copy()\n",
    "if len(input_size)==2:\n",
    "    input_size.append(3)\n",
    "            \n",
    "model=Sequential([\n",
    "            KL.Conv2D(filters=class_number,\n",
    "                      kernel_size=1,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='softmax',\n",
    "                     input_shape=input_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2975 image files, 8925 annotation files\n",
      "Found 500 image files, 1500 annotation files\n"
     ]
    }
   ],
   "source": [
    "batch_size=2\n",
    "train_dataset=cityscapes(config.dataset,split='train',bchw=False)\n",
    "train_loader=TD.DataLoader(dataset=train_dataset,batch_size=32, shuffle=True,drop_last=False)\n",
    "\n",
    "val_dataset=cityscapes(config.dataset,split='val',bchw=False)\n",
    "val_loader=TD.DataLoader(dataset=val_dataset,batch_size=32, shuffle=True,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_metrics = runningScore(class_number)\n",
    "name='empty_net'\n",
    "time_str = time.strftime(\"%Y-%m-%d___%H-%M-%S\", time.localtime())\n",
    "log_dir=os.path.join(config.training.log_dir,name,config.dataset.name,config.training.note,time_str)\n",
    "checkpoint_path=os.path.join(log_dir,\"{}_{}_best_model.pkl\".format(name, config.dataset.name))\n",
    "os.makedirs(log_dir,exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "best_iou=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([32, 36, 36, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "for images,labels in train_loader:\n",
    "    print(type(images),images.shape)\n",
    "    print(type(labels),labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=images.data.numpy()\n",
    "np_labels=labels.data.numpy()\n",
    "b,h,w=np_labels.shape\n",
    "y=to_categorical(np_labels,class_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 36, 36, 3)\n",
      "(32, 36, 36, 20)\n",
      "['loss', 'acc']\n",
      "[0.0992285, 0.0021942516]\n",
      "<class 'numpy.ndarray'>\n",
      "(32, 36, 36, 20)\n",
      "<class 'list'>\n",
      "[0.09916329, 0.0022907022]\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "train_outputs=model.train_on_batch(x=x,y=y)\n",
    "print(model.metrics_names)\n",
    "print(train_outputs)\n",
    "predict_outputs=model.predict_on_batch(x)\n",
    "print(type(predict_outputs))\n",
    "print(predict_outputs.shape)\n",
    "test_outputs=model.test_on_batch(x,y)\n",
    "print(type(test_outputs))\n",
    "print(test_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
