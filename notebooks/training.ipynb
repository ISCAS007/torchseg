{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traing model in notebook\n",
    "- start with a best model weight\n",
    "- load and train it with different config\n",
    "- save the new best model if miou increased\n",
    "\n",
    "# Target\n",
    "- best optimizer + lr + weight decay + lr_mult\n",
    "- best batch size + data augmentation\n",
    "- best loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/yzbx/git/torchseg', '', '/home/yzbx/git/torchseg/notebooks', '/home/yzbx/git/gnu/models/research', '/home/yzbx/git/gnu/models/research/slim', '/home/yzbx/bin/miniconda3/envs/new/lib/python36.zip', '/home/yzbx/bin/miniconda3/envs/new/lib/python3.6', '/home/yzbx/bin/miniconda3/envs/new/lib/python3.6/lib-dynload', '/home/yzbx/bin/miniconda3/envs/new/lib/python3.6/site-packages', '/home/yzbx/bin/miniconda3/envs/new/lib/python3.6/site-packages/cityscapesscripts-1.0.0-py3.6-linux-x86_64.egg', '/home/yzbx/bin/miniconda3/envs/new/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg', '/home/yzbx/bin/miniconda3/envs/new/lib/python3.6/site-packages/IPython/extensions', '/home/yzbx/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "project_dir=os.path.expanduser('~/git/torchseg')\n",
    "os.chdir(project_dir)\n",
    "sys.path.insert(0,project_dir)\n",
    "print(sys.path)\n",
    "from utils.config import get_parser,get_config\n",
    "from utils.disc_tools import get_newest_file\n",
    "from models.pspnet import pspnet\n",
    "import glob\n",
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.survey import dataset_survey\n",
    "from utils.metrics import runningScore,get_scores\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert input shape is (240, 240) ******************************\n",
      "{'model': {'upsample_type': 'bilinear', 'auxnet_type': 'bilinear', 'upsample_layer': 4, 'auxnet_layer': 4, 'cross_merge_times': 1, 'use_momentum': True, 'backbone_pretrained': True, 'use_bn': True, 'use_dropout': False, 'use_bias': True, 'eps': 1e-05, 'momentum': 0.01, 'learning_rate': 0.0001, 'optimizer': 'adam', 'lr_weight_decay': 0.0001, 'lr_momentum': 0.9, 'use_lr_mult': True, 'changed_lr_mult': 2.0, 'new_lr_mult': 5.0, 'use_reg': False, 'use_class_weight': False, 'class_weight_alpha': 0.0, 'focal_loss_gamma': -1.0, 'focal_loss_alpha': 1.0, 'l2_reg': 1e-05, 'backbone_name': 'vgg16_bn', 'backbone_freeze': False, 'layer_preference': 'first', 'edge_seg_order': 'same', 'midnet_pool_sizes': [6, 3, 2, 1], 'midnet_scale': 5, 'midnet_name': 'psp', 'edge_bg_weight': 0.01, 'edge_base_weight': 1.0, 'edge_power': 0.9, 'aux_base_weight': 1.0, 'input_shape': [240, 240], 'midnet_out_channels': 512, 'class_number': 21}, 'dataset': {'edge_class_num': 2, 'edge_width': 10, 'edge_with_gray': False, 'with_edge': False, 'norm_ways': 'pytorch', 'root_path': '/home/yzbx/.cv/datasets/VOC', 'txt_note': 'voc2012', 'txt_path': '/home/yzbx/git/torchseg/dataset/txt', 'foreground_class_ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'labels': ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'], 'counts': [182014429, 1780580, 758311, 2232247, 1514260, 1517186, 4375622, 3494749, 6752515, 2861091, 2060925, 3381632, 4344951, 2283739, 2888641, 11995853, 1670340, 2254463, 3612229, 3984238, 2349235], 'ignore_index': 255, 'resize_shape': [240, 240], 'name': 'voc2012', 'augmentations_blur': True, 'dataset_use_part': 0}, 'args': {'n_epoch': 50, 'log_dir': '/home/yzbx/tmp/logs/pytorch', 'summary_image': False, 'save_model': True, 'iou_save_threshold': 0.5, 'batch_size': 4, 'augmentation': True, 'augmentations_rotate': True, 'net_name': 'pspnet', 'note': 'jupyter001'}}\n",
      "use_bn True\n",
      "use_dropout False\n",
      "use_bias True\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "no weight file found under /home/yzbx/tmp/logs/pytorch/pspnet/voc2012/jupyter001, \n please specify checkpoint path",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3ce82b3a6592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mckpt_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'**'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'*.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'no weight file found under %s, \\n please specify checkpoint path'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_newest_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no checkpoint file given, auto find %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: no weight file found under /home/yzbx/tmp/logs/pytorch/pspnet/voc2012/jupyter001, \n please specify checkpoint path"
     ]
    }
   ],
   "source": [
    "#checkpoint_path=os.path.expanduser('~/tmp/logs/pytorch/pspnet/voc2012/voc_benchmark/2018-10-26___17-00-45/model-last-49.pkl')\n",
    "parser=get_parser()\n",
    "argv='--upsample_layer=4 --use_momentum=True --backbone_name=vgg16_bn --use_lr_mult=True --changed_lr_mult=2 --new_lr_mult=5 --midnet_scale=5 --batch_size=4 --momentum=0.01 --dataset_name=VOC2012 --note=jupyter001 --save_model=True --n_epoch=50'\n",
    "args=parser.parse_args(argv.split(' '))\n",
    "config=get_config(args)\n",
    "print(config)\n",
    "\n",
    "model = globals()[args.net_name](config)\n",
    "\n",
    "checkpoint_path=None\n",
    "if checkpoint_path is None:\n",
    "    log_dir = os.path.join(config.args.log_dir, model.name,\n",
    "                       config.dataset.name, config.args.note)\n",
    "    ckpt_files=glob.glob(os.path.join(log_dir,'**','model-best-*.pkl'),recursive=True)\n",
    "\n",
    "    # use best model first, then use the last model, because the last model will be the newest one if exist.\n",
    "    if len(ckpt_files)==0:\n",
    "        ckpt_files=glob.glob(os.path.join(log_dir,'**','*.pkl'),recursive=True)\n",
    "\n",
    "    assert len(ckpt_files)>0,'no weight file found under %s, \\n please specify checkpoint path'%log_dir\n",
    "    checkpoint_path=get_newest_file(ckpt_files)\n",
    "    print('no checkpoint file given, auto find %s'%checkpoint_path)\n",
    "else:\n",
    "    assert os.path.exists(checkpoint_path),'checkpoint path %s not exist'%checkpoint_path\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "state_dict=torch.load(checkpoint_path)\n",
    "if 'model_state' in state_dict.keys():\n",
    "    model.load_state_dict(state_dict['model_state'])\n",
    "else:\n",
    "    model.load_state_dict(state_dict)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cycle lr mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch=15\n",
    "net = model\n",
    "config.args.note+='_cycle'\n",
    "for times in range(3):\n",
    "    config.args.n_epoch=n_epoch*2**times\n",
    "    config.args.note = note+'_%d'%times\n",
    "    assert net.config.args.n_epoch==config.args.n_epoch\n",
    "    keras_fit(model=net,train_loader=train_loader,val_loader=val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:new]",
   "language": "python",
   "name": "conda-env-new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
