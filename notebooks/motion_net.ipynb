{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data02/jiaxin15/bin/miniconda3/envs/env3/lib/python3.6/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch.utils.data as td\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "project_dir=os.path.expanduser('~/git/torchseg')\n",
    "os.chdir(project_dir)\n",
    "\n",
    "from dataset.fbms_dataset import fbms_dataset\n",
    "from dataset.cdnet_dataset import cdnet_dataset\n",
    "from models.motion_stn import motion_stn,motion_net\n",
    "from models.motionseg.motion_fcn import motion_fcn,motion_fcn_stn\n",
    "from models.motionseg.motion_unet import motion_unet,motion_unet_stn\n",
    "from dataset.dataset_generalize import image_normalizations\n",
    "from utils.torch_tools import get_ckpt_path,load_ckpt\n",
    "from utils.disc_tools import show_images,show_tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size 353\n",
      "val dataset size 367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data02/jiaxin15/git/torchseg/models/motionseg/motion_backbone.py:96: UserWarning: unknown net name motion_attention for max extracted layer index\n",
      "  warnings.warn('unknown net name {} for max extracted layer index'.format(config.net_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no checkpoint file given, auto find /data02/jiaxin15/tmp/logs/motion/motion_attention/FBMS/task236_motion_attention/2019-09-02___22-56-53/model-last-100.pkl\n"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict as edict\n",
    "from utils.config import load_config\n",
    "from models.motionseg.motion_utils import get_model,get_dataset\n",
    "config_txt='/data02/jiaxin15/tmp/logs/motion/motion_attention/FBMS/task236_motion_attention/2019-09-02___22-56-53/config.txt'\n",
    "config=load_config(config_txt)\n",
    "\n",
    "dataset_loaders={}\n",
    "for split in ['train','val']:\n",
    "    xxx_dataset=get_dataset(config,split)\n",
    "    batch_size=config.batch_size if split=='train' else 1\n",
    "    xxx_loader=td.DataLoader(dataset=xxx_dataset,batch_size=batch_size,shuffle=True,drop_last=False,num_workers=2)\n",
    "    dataset_loaders[split]=xxx_loader\n",
    "\n",
    "if config['net_name'] in ['motion_stn','motion_net']:\n",
    "    model=globals()[config['net_name']]() \n",
    "else:\n",
    "    model=get_model(config)\n",
    "# support for cpu/gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "log_dir=os.path.dirname(config_txt)\n",
    "checkpoint_path = get_ckpt_path(log_dir)\n",
    "model=load_ckpt(model,checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8369, device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0') 1.0 tensor(0., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0') tensor(167971, device='cuda:0') tensor(32733, device='cuda:0') tensor(200704, device='cuda:0') 4 tensor(0., device='cuda:0') tensor(0., device='cuda:0') 4\n",
      "tensor(0.8386, device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0') 1.0\n",
      "tensor(0, device='cuda:0') tensor(36, device='cuda:0') tensor(244545, device='cuda:0') tensor(47019, device='cuda:0') tensor(291600, device='cuda:0') tensor(0., device='cuda:0') tensor(0., device='cuda:0') 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x2b5497d5add8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data02/jiaxin15/bin/miniconda3/envs/env3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 399, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data02/jiaxin15/bin/miniconda3/envs/env3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 378, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/data02/jiaxin15/bin/miniconda3/envs/env3/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/data02/jiaxin15/bin/miniconda3/envs/env3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 151, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/data02/jiaxin15/bin/miniconda3/envs/env3/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/data02/jiaxin15/bin/miniconda3/envs/env3/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/data02/jiaxin15/bin/miniconda3/envs/env3/lib/python3.6/multiprocessing/connection.py\", line 494, in Client\n",
      "    deliver_challenge(c, authkey)\n",
      "  File \"/data02/jiaxin15/bin/miniconda3/envs/env3/lib/python3.6/multiprocessing/connection.py\", line 722, in deliver_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/data02/jiaxin15/bin/miniconda3/envs/env3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/data02/jiaxin15/bin/miniconda3/envs/env3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/data02/jiaxin15/bin/miniconda3/envs/env3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    }
   ],
   "source": [
    "normer=image_normalizations(ways='-1,1')\n",
    "model.eval()\n",
    "from models.motionseg.motion_utils import Metric_Acc\n",
    "for split in ['train','val']:\n",
    "    metric_acc=Metric_Acc()\n",
    "    for frames,gt in dataset_loaders[split]:\n",
    "        images = [torch.autograd.Variable(img.to(device).float()) for img in frames]\n",
    "        origin_labels=torch.autograd.Variable(gt.to(device).long())\n",
    "        labels=F.interpolate(origin_labels.float(),size=config.input_shape,mode='nearest').long()\n",
    "        outputs=model.forward(images)\n",
    "        \n",
    "        origin_mask=F.interpolate(outputs['masks'][0], size=origin_labels.shape[2:4],mode='nearest')\n",
    "        metric_acc.update(origin_mask,origin_labels)\n",
    "        \n",
    "        acc=metric_acc.get_acc()\n",
    "        precision=metric_acc.get_precision()\n",
    "        recall=metric_acc.get_recall()\n",
    "        fmeasure=metric_acc.get_fmeasure()\n",
    "        avg_p,avg_r,avg_f=metric_acc.get_avg_metric()\n",
    "        print(acc,precision,recall,fmeasure,avg_p,avg_r,avg_f)\n",
    "        print(metric_acc.tp,metric_acc.fp,metric_acc.tn,metric_acc.fn,metric_acc.count,\n",
    "              metric_acc.sum_p,metric_acc.sum_r,metric_acc.sum_f,metric_acc.img_count)\n",
    "#         show_tensor_list(images,['main','aux'],normer)\n",
    "#         show_tensor_list([gt],[split+' motion label'])\n",
    "#         masks=[torch.argmax(x,dim=1,keepdim=True) for x in outputs['masks']]\n",
    "#         show_tensor_list(masks,[split+' motion mask level '+str(idx) for idx,t in enumerate(outputs['masks'])])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env3]",
   "language": "python",
   "name": "conda-env-env3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
